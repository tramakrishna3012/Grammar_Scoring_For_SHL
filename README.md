# ğŸ“ Grammar Correction System using Fine-Tuned T5 Transformer

This project builds a **Grammar Correction System** using the **T5 Transformer model**, aimed specifically at correcting English-language text generated via voice input. The system supports training from scratch on grammar datasets, evaluates grammatical accuracy, and offers inference from both typed and spoken input.

We have fine-tuned a **T5 Transformer** for this task because:

- T5 (Text-to-Text Transfer Transformer) treats every NLP task as a text generation problem, making it naturally suited for grammar correction.
- It has shown strong performance on a wide range of language tasks with minimal task-specific modifications.
- Its encoder-decoder architecture allows effective mapping from incorrect to corrected text.

---

## ğŸ’½ Table of Contents

- [ğŸ” Introduction](#-introduction)
- [âš™ï¸ Installation](#-installation)
- [ğŸ“¥ Data Collection](#-data-collection)
- [ğŸ” Data Examination](#-data-examination)
- [ğŸ§¹ Dataset Preprocessing](#-dataset-preprocessing)
- [ğŸ‹ï¸ Training](#-training)
- [ğŸ“ˆ After Training Evaluating](#-after-training-evaluating)
- [ğŸ§  Inference](#-inference)
- [ğŸš€ Further Improvement](#-further-improvement)

---

## ğŸ” Introduction

This project trains a **T5 Transformer model** to correct grammatical errors, especially in voice-generated English sentences. It includes:

- Data generation from `JFLEG` dataset.
- Grammar scoring.
- Fine-tuning the model using HuggingFace `transformers`.
- Voice-based input for real-time correction.

---

## âš™ï¸ Installation

```bash
# Clone repo
git clone https://github.com/your-username/grammar-correction-t5.git
cd grammar-correction-t5

# Install dependencies
# Tested on Python 3.9
pip install -r requirements.txt
```

**Key Libraries:**

- `transformers`
- `datasets`
- `torch`
- `pandas`
- `speechrecognition`, `sounddevice`, `scipy` (for voice input)
- `python-Levenshtein` (for grammar scoring)

---

## ğŸ“¥ Data Collection

We use the [**JFLEG dataset**](https://huggingface.co/datasets/jfleg) via HuggingFace `datasets`.

Code Reference: [`data_utils.py`](./data_utils.py)

```python
from data_utils import load_jfleg_dataset
dataset = load_jfleg_dataset("validation")
```

---

## ğŸ” Data Examination

The dataset contains sentences with multiple reference corrections. These are processed and formatted into a CSV file.

```python
from data_utils import generate_csv
generate_csv("train.csv", dataset, limit_to_one_target=True)
```

---

## ğŸ§¹ Dataset Preprocessing

Each sentence is prefixed with the `"grammar:"` tag, tokenized using the `T5Tokenizer`, and structured into HuggingFace `Dataset` objects.

Script: [`model_utils.py`](./model_utils.py)

---

## ğŸ‹ï¸ Training

Train the model from scratch (starting from `vennify/t5-base-grammar-correction`) using `Trainer`.

Run via: [`main.py`](./main.py)

```bash
python main.py
```

This includes:

- Splitting JFLEG dataset into train/eval
- Generating CSVs
- Training with early stopping and evaluation
- Saving the fine-tuned model

---

## ğŸ“ˆ After Training Evaluating

After training, the model is evaluated on unseen examples. Example output:

```
Original: This sentences, has bads grammar and spelling!
Corrected: This sentence has bad grammar and spelling!
Grammar score: 88.7
```

---

## ğŸ§  Inference

### ğŸ¡ Text Input

Use `inference.py`:

```python
correct_text(model, tokenizer, "She no went there.")
```

### ğŸ—£ï¸ Voice Input

Run voice-based grammar correction via:

```python
from voice_app import voice_input_to_text
voice_input_to_text()  # Records and transcribes input
```

Runs automatic correction and scoring:

```python
corrected = correct_text(model, tokenizer, transcribed_text)
```

---

## ğŸš€ Further Improvement

- Transfer select evaluation examples into training set for more realistic learning.
- Tune hyperparameters with grid search (learning rate, batch size, epochs).
- Train on multilingual data to support grammar correction in other languages.
- Add custom decoder layers to refine correction quality.
- Try other models like `BART`, `GPT`, `T0`, or `mT5`.

---

## ğŸ“ File Structure

```
.
â”œâ”€â”€ main.py                # End-to-end pipeline
â”œâ”€â”€ data_utils.py          # Load & preprocess JFLEG dataset
â”œâ”€â”€ model_utils.py         # Train and evaluate T5 model
â”œâ”€â”€ inference.py           # Text-based inference logic
â”œâ”€â”€ grammer_score.py       # Grammar scoring using Levenshtein distance
â”œâ”€â”€ voice_app.py           # Voice recording and transcription
â”œâ”€â”€ train.csv / eval.csv   # Auto-generated CSVs
â””â”€â”€ README.md              # You're here
```

---

## ğŸ§  Author

Built by T Rama Krishna. Inspired by the need to improve grammar in voice-based interfaces.

